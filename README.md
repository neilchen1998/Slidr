# slidr (8 Puzzle Solver)

This project solves the famous 8 Puzzle problem.

## Summary

8 Puzzle problem is a simple version of [15 Puzzle problem](https://en.wikipedia.org/wiki/15_puzzle).
In this project, [A* algorithm](http://theory.stanford.edu/~amitp/GameProgramming/AStarComparison.html) is used to solve the problem.
Each time through the main loop, A* examines the state $n$ sucht that it has the lowest value of $f(n) = g(n) + h(n)$.
$g(n)$ is the actual cost (in this case, the number of moves) of a state from the starting state.
$h(n)$ is the heuristic cost of a state to the goal, [Manhattan Distance](https://xlinux.nist.gov/dads/HTML/manhattanDistance.html) is used in this project. Then it will explore all possible movements (left, right, up, down),
and keep on until it reaches the goal.

## Requirements

The requirements are:

- CMake 3.18 or better; 4.0+ highly recommended
- A C++20 compatible compiler ([gcc](https://gcc.gnu.org/) or [llvm](https://llvm.org/))
- The Boost libararies
- Git
- Doxygen (optional, highly recommended)
- Conda/Miniconda (optional, highly recommended)
- Python (for gprof visualization)
- Boost library (for benchmarking)
- [fmt](https://github.com/fmtlib/fmt) 11.0 or better (will automatically install if not present)

## How to Use

Add this to your CMakeLists.txt:

```cmake
FetchContent_Declare(
  slidr
  GIT_REPOSITORY https://github.com/neilchen1998/slidr
  GIT_TAG        v2.0)
  FetchContent_MakeAvailable(slidr)
```

Add this if you would like to skip building the example:

```cmake
set(BUILD_EXAMPLES OFF CACHE BOOL "" FORCE)
```

## Instructions

To configure:

```bash
cmake -S . -B build
```

Add `--toolchain=./<your_toolchain_file>.toolchain` if you want to use your own toolchain.

Add `-GNinja` if you have Ninja.

To build without example:

```bash
cmake --build build
```

To build with example:

```bash
cmake --build build -DBUILD_EXAMPLES=ON
```

To test (`--target` can be written as `-t` in CMake 3.15+):

```bash
cmake --build build --target test
```

To run the binary with example layout:

```bash
./build/apps/app
```

To run the binary with a custom puzzle layout (use 1 to 8 and 'x' or 'X' for the empty space):

```bash
./build/apps/app <puzzle>
```

To build and test:

```bash
cmake --build build -DCMAKE_BUILD_TYPE=Test && cmake --build build --target test
```

To build docs (requires Doxygen, output in `build/docs/html`):

```bash
cmake --build build --target docs
```

To build and run benchmark:

```bash
cmake -S . -B build -DCMAKE_BUILD_TYPE=Benchmark && ./build/bench/<name_of_benchmark>
```

To run the Unix performance analysis tool (tested only on Linux):

```bash
cmake -S . -B build -DCMAKE_BUILD_TYPE=Gprof && ./build/gprof/solverbenchmark && gprof ./build/gprof/solverbenchmark gmon.out > ./build/gprof/analysis.txt
```

To create and activate an environment if using conda:

```bash
conda create -n <env_name> && conda activate <env_name>
```

To install all dependencies:

```bash
pip install -r requirements.txt
```

To visualize gprof:

```bash
./build/gprof/solverbenchmark && gprof ./build/gprof/solverbenchmark | gprof2dot | dot -Tpng -o output.png
```

## Example Result

This is how you would use the solver:

```cpp
#include <slidr/solver/solver.hpp>

auto s = slidr::Solver(layout);
auto [isSolved, totalIters] = s.SolvePuzzle();

fmt::println("Numbers of moves: {}", s.GetNumOfMoves());
fmt::println("Solution: {}", s.GetSolution());
s.PrintPath();
```

## Example Output

Run the example file:

```bash
./build/apps/app
```

Or enter a custom layout:

```bash
./build/apps/app 1274x5836
```

NOTE: Do not leave spaces between pieces and use **x** or **X** to denote the empty piece of the puzzle.

This is the default puzzle and its output:

<table>
  <tr>
    <td>5</td>
    <td>3</td>
    <td>6</td>
  </tr>
  <tr>
    <td>2</td>
    <td></td>
    <td>8</td>
  </tr>
  <tr>
    <td>4</td>
    <td>1</td>
    <td>7</td>
  </tr>
</table>

```
No additional argument is provided! An example puzzle layout will be used.
Done in: 67 µs  # of iterations: 65     Total moves: 14
Step: 0
5 3 6
2 x 8
4 1 7
Step: 1
5 3 6
2 1 8
4 x 7
Step: 2
5 3 6
2 1 8
4 7 x
Step: 3
5 3 6
2 1 x
4 7 8
Step: 4
5 3 x
2 1 6
4 7 8
Step: 5
5 x 3
2 1 6
4 7 8
Step: 6
5 1 3
2 x 6
4 7 8
Step: 7
5 1 3
x 2 6
4 7 8
Step: 8
x 1 3
5 2 6
4 7 8
Step: 9
1 x 3
5 2 6
4 7 8
Step: 10
1 2 3
5 x 6
4 7 8
Step: 11
1 2 3
x 5 6
4 7 8
Step: 12
1 2 3
4 5 6
x 7 8
Step: 13
1 2 3
4 5 6
7 x 8
Step: 14
1 2 3
4 5 6
7 8 x
Moves: ↑←↓↓→↑→↓←↑→↑←←
```

## Gprof

[Gprof](https://man7.org/linux/man-pages/man1/gprof.1.html) is a performance analysis tool running on Unix systems.
It can help you see what how much time does each function take.
It is useful for code optimization.
This is the visualization of the result of gprof which is generated by gprof2dot:

![Gprof Visualization](https://github.com/neilchen1998/8-Puzzle/blob/main/gprof-visualization.png?raw=true)

## Notes

### Hash Algorithm

A simple way to hash two values is using `boost::hash_combine` from the [Boost library](https://www.boost.org/).
Or as this [post](https://stackoverflow.com/questions/2590677/how-do-i-combine-hash-values-in-c0x) suggests, use the following:

```cpp
template <class T>
inline void hash_combine(std::size_t& seed, const T& v)
{
    std::hash<T> h;
    seed ^= h(v) + 0x9e3779b9 + (seed << 6) + (seed >> 2);
    // seed ^= (std::hash<T>{}(u) << 1); // this MIGHT get the job done, it passess all the test cases
}
```

There is no significant performance difference between two approaches according to the benchmark that can be found in `bench/mathbenchlib`.
The archeive file size when using `boost::hash_combine` and that when using `hash_combine` are identical.

An even more simplified version as shown in the comment *MIGHT* work.
It passes all the test cases in the repo.
But it is not advised.

| benchmark       | op/s | ns/op |
| :-----------| :------------ | ----: |
| hash_vector | 74,615,800.46 | 13.40 |
| hash_range  | 90,301,886.39 | 11.07 |

### `const std::vector<T>& vec` vs. `std::span<T> s`

According to the benchmark `bench/mathbenchlib` powered by [nanobench](https://github.com/martinus/nanobench) and [Quick C++ Benchmark](https://quick-bench.com/),
there is no significant performance difference
between hashing a `const std::vector<T>& vec` and `std::span<T> s`.
The overhead of converting a `std::vector<T> vec` to `std::span<T> s` is minimal.
Since this project uses C++20, this is the way to go.

### Manhattan Distance Calculation

[Manhattan Distance](https://xlinux.nist.gov/dads/HTML/manhattanDistance.html) is used to calculate the heuristic value of a puzzle in a given state.

In our problem, $p_1$ represents the goal position and $p_2$ represents the current position of a piece of the puzzle and the formula is
$|x_1 - x_2| + |y_1 - y_2|$, where $x$ denotes the row position and $y$ denotes the column position.

There are three implementations, using a simple for-loop, using `std::accumulate`, and using `std::reduce`:

```cpp
int GetManhattanDistance(std::span<int> s)
{
    int manhattanDistance = 0;
    for (auto i = 0; i < constants::EIGHT_PUZZLE_NUM; ++i)
    {
        if (s[i] != constants::EMPTY)
        {
            int curRow = (s[i] - 1) / constants::EIGHT_PUZZLE_SIZE;
            int curCol = (s[i] - 1) % constants::EIGHT_PUZZLE_SIZE;

            int goalRow = i / constants::EIGHT_PUZZLE_SIZE;
            int goalCol = i % constants::EIGHT_PUZZLE_SIZE;

            manhattanDistance += (std::abs(goalRow - curRow) + std::abs(goalCol - curCol));
        }
    }

    return manhattanDistance;
}
```

```cpp
int GetManhattanDistanceAccumulate(std::span<int> s)
{
    auto v = std::views::iota(0, constants::EIGHT_PUZZLE_NUM);
    return std::accumulate(
        v.begin(),
        v.end(),
        0,
        [&](int acc, int i) {
            if (s[i] == constants::EMPTY)
            return acc;

            int curRow = (s[i] - 1) / constants::EIGHT_PUZZLE_SIZE;
            int curCol = (s[i] - 1) % constants::EIGHT_PUZZLE_SIZE;
            int goalRow = i / constants::EIGHT_PUZZLE_SIZE;
            int goalCol = i % constants::EIGHT_PUZZLE_SIZE;

            return acc + std::abs(goalRow - curRow) + std::abs(goalCol - curCol);
        }
    );
}
```

```cpp
int GetManhattanDistanceReduce(std::span<int> s)
{
    auto v = std::views::iota(0, constants::EIGHT_PUZZLE_NUM);
    return std::reduce(
        v.begin(),
        v.end(),
        0,
        [&](int acc, int i) {
            if (s[i] == constants::EMPTY)
                return acc;

            int curRow = (s[i] - 1) / constants::EIGHT_PUZZLE_SIZE;
            int curCol = (s[i] - 1) % constants::EIGHT_PUZZLE_SIZE;
            int goalRow = i / constants::EIGHT_PUZZLE_SIZE;
            int goalCol = i % constants::EIGHT_PUZZLE_SIZE;

            return acc + std::abs(goalRow - curRow) + std::abs(goalCol - curCol);
        }
    );
}
```

`std::reduce` utilizes parallelism which in theory be faster than `std::accumulate`.
In our case the order of the operations does not matter, therefore we can use `std::reduce`.
Nonetheless, based on the benchmark, the three different approaches do not have discernable difference in terms of speed.

| benchmark       | op/s           | ns/op|
| :---------------| :------------- | ---: |
| for loop        | 160,295,728.06 | 6.24 |
| std::accumulate | 156,853,151.47 | 6.38 |
| std::reduce     | 157,072,439.95 | 6.37 |

### `std::priortiy_queue` vs. Bucket Queue

The most commonly used data structure for the queue is a [priority queue](https://en.cppreference.com/w/cpp/container/priority_queue.html).
It has `O(log n)` for insertion, `O(log n)` for deletion, and `O(1)` for peak operation.
Whenever the solver enters the node with the lowest value of `f(n)`, it will need to pop out the state from the priority queue.
And when the solver finds a new valid state, it will need to add the new state to the priority queue.
Both operations are done frequently and both operations have a time complexity of `O(log n)`.
Therefore a better data structure is needed.
A [bucket queue](https://en.wikipedia.org/wiki/Bucket_queue) is choosen to replace `std::priortiy_queue`.
A bucket queue has `O(1)` for insertion, `O(#priorities)` for deletion, and `O(1)` for peak operation.
Therefore, a bucket queue is faster than a `std::priortiy_queue`.
The default number of buckets is **64**.
The rationale behind that is due to the maximum number of moves is [31](http://w01fe.com/blog/2009/01/the-hardest-eight-puzzle-instances-take-31-moves-to-solve/).
In this benchmark, a *bucket queue* with 32 buckets is added for eductional purposes.
However, the downsize of using a bucket queue is the underlying container is *std::vector* and reallocations will be needed if there are two many nodes in a single bucket.
This downside is pronounced when the given puzzle falls under the category of easy (less than 20 steps to solve).
In this project, 9 test cases are used for benchmarking.
Those are divided into three categories: **easy**, **medium**, and **hard**.
**easy** takes less than 20 steps to solve, **medium** takes between 20 and 30, and **hard** takes 31 steps (which is the most steps possible).
The result is shown in the following table:

| Group 1: Easy Puzzles      | op/s     |
| :------------------------- | :------- |
| Priority Queue Solver      | 5,567.37 |
| Bucket Queue Solver        | 4,130.10 |
| Bucket Queue Solver (32)   | 4,088.10 |

| Group 2: Medium Puzzles      | op/s   |
| :------------------------- | :----- |
| Priority Queue Solver      | 334.56 |
| Bucket Queue Solver        | 424.59 |
| Bucket Queue Solver (32)   | 426.45 |

| Group 3: Hard Puzzles      | op/s   |
| :------------------------- | :----- |
| Priority Queue Solver      | 123.22 |
| Bucket Queue Solver        | 139.41 |

We can see that *bucket queue* wins in both the second group and the third group.
This result aligns with the characteristic of *bucket queue* as you saw earlier.
The *bucket queue* with 32 buckets performs similar to that with 64 buckets.
However, it fails to solve the third category of puzzles due those puzzles have *f* value greater than 32.

### Linear Conflict

Piece A (the lower index) and piece B (the higher index) are in a linear confict if both of them are on the goal row (or column) and the value of piece A is greater than that of piece B.
For instance, **3** and **1** are in a linear conflict since both pieces are in their goaal row and **3** is greater than **1**.

<table>
  <tr>
    <td>3</td>
    <td>x</td>
    <td>1</td>
  </tr>
  <tr>
    <td>x</td>
    <td>x</td>
    <td>x</td>
  </tr>
  <tr>
    <td>x</td>
    <td>x</td>
    <td>x</td>
  </tr>
</table>

However, there is no linear conflict in the following puzzle.
Notice that **3** and **6** are not in theira goal positions but **3** is smaller than **6**.

<table>
  <tr>
    <td>1</td>
    <td>2</td>
    <td>x</td>
  </tr>
  <tr>
    <td>4</td>
    <td>5</td>
    <td>3</td>
  </tr>
  <tr>
    <td>7</td>
    <td>8</td>
    <td>6</td>
  </tr>
</table>

The total heuristic value *h(n)* is now the Manhattan distance plus two times the number of linear conflicts of the puzzle. This is still admissible, meaning that the value is still less than the actual number of steps that is required to solve the puzzle.

The following table is the comparison between using the Manhattan distance and using the Manhatatn distance plus the linear conflict. The improvement is huge for easy puzzles. Significant improvement can also be observed for both medium and hard puzzles as well.

| Group 1: Easy Puzzles      | Manhattan Dist. | M. Dist. + Linear Cnflct. | Improvement |
| :------------------------- | :------- | :------- | :------- |
| Priority Queue Solver      | 5,567.37 | 13,713.16| 246.3% |
| Bucket Queue Solver        | 4,130.10 | 7,035.54 | 170.3% |
| Bucket Queue Solver (32)   | 4,088.10 | 7,010.57 | 171.5% |

| Group 2: Medium Puzzles      | Manhattan Dist. | M. Dist. + Linear Cnflct. | Improvement |
| :------------------------- | :----- | :------- | :------- |
| Priority Queue Solver      | 334.56 | 607.25 | 181.5% |
| Bucket Queue Solver        | 424.59 | 484.35 | 114.1% |
| Bucket Queue Solver (32)   | 426.45 | 480.73 | 112.7% |

| Group 3: Hard Puzzles      | Manhattan Dist. | M. Dist. + Linear Cnflct. | Improvement |
| :------------------------- | :----- | :------- | :------- |
| Priority Queue Solver      | 123.22 | 194.19 | 157.6% |
| Bucket Queue Solver        | 139.41 | 186.12 | 133.5% |

### Interface Library

An [interface library](https://cliutils.gitlab.io/modern-cmake/chapters/basics.html) is for a header-only library.
It does not create an output library. But it can and will be used by other libraries.
In this project, **constantslib**, **mathlib**, and **solverlib** are all interface libraries.
**constantslib** is where all constants are defined.
**mathlib**, and **solverlib** are both template classes.

### Use Pointers

After changing the data type in our `std::priortiy_queue`, a significant performance increase is observed. NOTE: those are using *-Ofast* [compiler flag](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html).

| benchmark             | op/s     | ns/op     |
| :---------------------| :------- | :----------- |
| Priority Queue Solver | 2,089.45 | 478,594.10 |
| Priority Queue Solver (using pointers) | 2,578.67 | 387,796.43 |
| Bucket Queue Solver   | 1,876.87 | 532,802.08 |
| Bucket Queue Solver (using pointers)   | 2,139.18 | 467,469.06 |

### Fold Expressions

[Fold expressions](https://en.cppreference.com/w/cpp/language/fold.html?ref=blog.yuo.be) were introduced in C++17.
This is a way to reduce a template parameter pack over a binary operator.
A template parameter pack is a template parameter that accepts zero or more arguments.
*hash_combine* uses fold expressions to take multiple arguments and hashes them in left order.
For instance,

```cpp
hash_combine(h, u, v);
```

is equivalent to

```cpp
hash_combine(h, u);
hash_combine(h, v);
```

This is extremely useful since we need to hash the value and the position of the current puzzle.
Hence, we only need to write all the arguments that we need in a single line of code instead of two lines.

# FetchContent

**FetchContent** is used to managed external dependencies.
It fetches dependencies at configuration time and those dependencies will be available at compilation time.
In this project, if a version of fmt library (newer than 11.0.0) is available on the system, then the version on the system will be used. Otherwise, fmt 11.2.0 will be fetched, compiled, and be used.
This approach is flexible for the user since it does not require to download the library.

## Reference

- [gprof2dot](https://pypi.org/project/gprof2dot/)
- [Visually Profile C++ Program Performance](https://www.youtube.com/watch?v=zbTtVW64R_I)
- [Global Constants](https://www.learncpp.com/cpp-tutorial/sharing-global-constants-across-multiple-files-using-inline-variables/)
- [Gprof Tutorial](https://www.thegeekstuff.com/2012/08/gprof-tutorial/)
- [Linear Conflict](https://cdn.aaai.org/AAAI/1996/AAAI96-178.pdf)
- [Fold Expressions](https://en.cppreference.com/w/cpp/language/fold.html?ref=blog.yuo.be)
